---
defaultBaseImageVersion: latest
properties:
- name: DEPLOYMENT_FILE
  value: ${DEPLOYMENT_FILE}
  type: text
stages:
- name: BUILD
  inputs:
  - type: git
    branch: ${GIT_BRANCH}
    service: ${GIT_REPO}
  triggers:
  - type: commit
  properties:
  - name: DOCKER_ROOT
    value: ${DOCKER_ROOT}
    type: text
  - name: DOCKER_FILE
    value: Dockerfile
    type: text  
  jobs:
  - name: Pre-build check
    type: builder
    build_type: cr
    artifact_dir: ''
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |-
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_prebuild.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_prebuild.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh")

      # Lints Dockerfile and checks presence of registry namespace.
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh")
  - name: Build Docker image
    type: builder
    build_type: cr
    artifact_dir: output
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/build_image.sh) and 'source' it from your pipeline job
      #    source ./scripts/build_image.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image.sh")

      # This script does build a Docker image into IBM Container Service private image registry.
      # Minting image tag using format: BUILD_NUMBER-BRANCH-COMMIT_ID-TIMESTAMP
      # Also copies information into a build.properties file, so they can be reused later on by other scripts (e.g. image url, chart name, ...)
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image.sh")
- name: VALIDATE
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  jobs:
  - name: Vulnerability Advisor
    type: tester
    test_type: vulnerabilityadvisor
    use_image_from_build_input: true
    fail_stage: false
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_vulnerabilities.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_vulnerabilities.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh")

      # Check for vulnerabilities of built image using Vulnerability Advisor
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh")
- name: DEPLOY
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text    
  jobs:
  - name: Pre-deploy check
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_predeploy.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_predeploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh")

      # Checks the cluster is ready, has a namespace configured with access to the private
      # image registry (using an IBM Cloud API Key). It also configures Helm Tiller service to later perform a deploy with Helm.
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh")
  - name: Deploy to Kubernetes
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/deploy_kubectl.sh) and 'source' it from your pipeline job
      #    source ./scripts/deploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh")

      # Infer parallel deployment configuration for canary app, using Git branch name
      echo -e "Updating $DEPLOYMENT_FILE to represent canary deployment: add label version, modify deployment name"
      #MK CANARY_DEPLOYMENT_FILE=canary-${DEPLOYMENT_FILE} # prefix original deployment file name
      #MK DEPLOYMENT_NAME=$( cat ${DEPLOYMENT_FILE} | yq r - -j | jq -r '. | select(.kind=="Deployment") | .metadata.name' ) # read deployment name
      #MK # Substitute deployment name and version label (yaml>json>substitute>yaml)
      #MK cat ${DEPLOYMENT_FILE} | yq r - -j | jq --arg l canary --arg n ${DEPLOYMENT_NAME}-canary '. | select(.kind=="Deployment") | .spec.template.metadata.labels.version = $l | .metadata.name = $n ' | yq r - > ${CANARY_DEPLOYMENT_FILE}
      #MK DEPLOYMENT_FILE=${CANARY_DEPLOYMENT_FILE} # replace original deployment file
      #MK cat ${DEPLOYMENT_FILE}

      opsys=linux  # or darwin, or windows
      curl -s https://api.github.com/repos/kubernetes-sigs/kustomize/releases/latest |\
        grep browser_download |\
        grep $opsys |\
        cut -d '"' -f 4 |\
        xargs curl -O -L
      mv kustomize_*_${opsys}_amd64 /usr/local/bin/kustomize
      chmod u+x /usr/local/bin/kustomize

      DEPLOYMENT_FILE=foo.yaml
      sed -i -e "s#iter8/reviews:istio-VERSION#$PIPELINE_IMAGE_URL#" kustomize/patch.yaml
      sed -i -e "s#VERSION#${IMAGE_TAG}#g" kustomize/patch.yaml
      cat kustomize/patch.yaml
      kustomize build kustomize -o ${DEPLOYMENT_FILE}
      cat ${DEPLOYMENT_FILE}
      CANARY_DEPLOYMENT_NAME=$(yq r ${DEPLOYMENT_FILE} metadata.name)f
      
      USE_ISTIO_GATEWAY=true
      source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh")
      # If already defined build.properties from prior build job, append to it.
      cp build.properties $ARCHIVE_DIR/ || :

      # IMAGE information from build.properties is used in Helm Chart deployment to set the release name
      echo "CANARY_DEPLOYMENT_NAME=${CANARY_DEPLOYMENT_NAME}"
      echo "CANARY_DEPLOYMENT_NAME=${CANARY_DEPLOYMENT_NAME}" >> $ARCHIVE_DIR/build.properties

- name: START CANARY EXPERIMENT (VIA ITER8)
  inputs:
  - type: job
    stage: DEPLOY
    job: Deploy to Kubernetes
  triggers:
    - type: stage
      enabled: false
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  - name: EXPERIMENT_TEMPLATE_FILE
    value: iter8/experiment.yaml
    type: text
  jobs:
  - name: Run iter8
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/create_experiment.sh) and 'source' it from your pipeline job
      #    source ./scripts/create_experiment.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/kalantar/canary-testing-istio-toolchain/master/scripts/create_experiment.sh")

      # Run canary experiment using iter8
      BASELINE_VERSION=reviews
      source <(curl -sSL "https://raw.githubusercontent.com/kalantar/canary-testing-istio-toolchain/master/scripts/create_experiment.sh")
- name: DELETE CANARY VERSION
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
    - type: stage
      enabled: false
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  jobs:
  - name: Stop iter8
    type: deployer
    target:
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      resource_group: ${PROD_RESOURCE_GROUP}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x

      # Stop iter8 experiment if still in progress
      echo "Stop iter8 if still running"
      #echo kubectl --namespace ${CLUSTER_NAMESPACE} patch ${EXPERIMENT_NAME} --type=json -p '[{"op": "add", "path": "/spec/assessment", "value": "override_fail"}]'
  - name: Discard canary deploy
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # Read deployment name from deployment manifest 
      echo "Delete canary deployment"
      
      opsys=linux  # or darwin, or windows
      curl -s https://api.github.com/repos/kubernetes-sigs/kustomize/releases/latest |\
        grep browser_download |\
        grep $opsys |\
        cut -d '"' -f 4 |\
        xargs curl -O -L
      mv kustomize_*_${opsys}_amd64 /usr/local/bin/kustomize
      chmod u+x /usr/local/bin/kustomize

      DEPLOYMENT_FILE=foo.yaml
      sed -i -e "s#iter8/reviews:istio-VERSION#$PIPELINE_IMAGE_URL#" kustomize/patch.yaml
      sed -i -e "s#VERSION#${IMAGE_TAG}#g" kustomize/patch.yaml
      cat kustomize/patch.yaml
      kustomize build kustomize -o ${DEPLOYMENT_FILE}
      cat ${DEPLOYMENT_FILE}
      
      kubectl delete deployment ${DEPLOYMENT_NAME}-canary --namespace ${CLUSTER_NAMESPACE}
      